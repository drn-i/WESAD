{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFGwX4mjUUt2",
        "outputId": "374ef619-9f6c-46a3-9bec-5490a175d2b5"
      },
      "outputs": [
        {
          "ename": "LoadError",
          "evalue": "ParseError:\n\u001b[90m# Error @ \u001b[0;0m\u001b]8;;file:///kaggle/working/In[7]#1:12\u001b\\\u001b[90mIn[7]:1:12\u001b[0;0m\u001b]8;;\u001b\\\n;python3 -m\u001b[48;2;120;70;70m pip install pandas numpy scipy scikit-learn matplotlib seaborn cvxopt xgboost kaggle\u001b[0;0m\n\u001b[90m#          └───────────────────────────────────────────────────────────────────────────────────┘ ── \u001b[0;0m\u001b[91mextra tokens after end of expression\u001b[0;0m",
          "output_type": "error",
          "traceback": [
            "ParseError:\n\u001b[90m# Error @ \u001b[0;0m\u001b]8;;file:///kaggle/working/In[7]#1:12\u001b\\\u001b[90mIn[7]:1:12\u001b[0;0m\u001b]8;;\u001b\\\n;python3 -m\u001b[48;2;120;70;70m pip install pandas numpy scipy scikit-learn matplotlib seaborn cvxopt xgboost kaggle\u001b[0;0m\n\u001b[90m#          └───────────────────────────────────────────────────────────────────────────────────┘ ── \u001b[0;0m\u001b[91mextra tokens after end of expression\u001b[0;0m",
            "",
            "Stacktrace:",
            " [1] top-level scope",
            "\u001b[90m   @\u001b[39m \u001b[90m\u001b[4mIn[7]:1\u001b[24m\u001b[39m"
          ]
        }
      ],
      "source": [
        "!pip install pandas numpy scipy scikit-learn matplotlib seaborn cvxopt xgboost shap kaggle\n",
        "\n",
        "!git clone https://github.com/drn-i/WESAD\n",
        "!git clone https://github.com/lciti/cvxEDA.git\n",
        "!cp /content/cvxEDA/src/* /content/WESAD/\n",
        "!rm -rf /content/cvxEDA\n",
        "!rm -rf /content/sample_data\n",
        "\n",
        "!mv /content/WESAD/* ./\n",
        "!rm -rf /content/WESAD\n",
        "\n",
        "# Line 277\n",
        "# df['label'] = df[['0', '1', '2']].idxmax(axis=1).astype(int)\n",
        "\n",
        "# Line 209\n",
        "# feat_names.append('_'.join([str(row), str(col)]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CdwE0lnWIVO",
        "outputId": "d471be25-65a0-40c0-d889-39a15f31b9e7"
      },
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"orvile/wesad-wearable-stress-affect-detection-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "!mkdir -p /content/data/WESAD\n",
        "!cp -r /root/.cache/kagglehub/datasets/orvile/wesad-wearable-stress-affect-detection-dataset/versions/1/WESAD/ /content/data/\n",
        "!cp -r /kaggle/input/wesad-wearable-stress-affect-detection-dataset/WESAD/ /content/data/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJENf0jQYJFI",
        "outputId": "c5d3c3d9-5058-4edb-f19a-5c5ed5fbf543"
      },
      "outputs": [],
      "source": [
        "!python data_wrangling.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATdwDvUWa986",
        "outputId": "14b48acc-ebd9-4871-9181-4e65a34ef922"
      },
      "outputs": [],
      "source": [
        "from readme_parser import rparser\n",
        "rparser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAnUNTLucSJb",
        "outputId": "161f4535-4960-4bc4-e34e-38c5fb668812"
      },
      "outputs": [],
      "source": [
        "# Train a tree-based model on the merged WESAD feature table and rank features by importance\n",
        "!python tree_feature_importance.py \\\n",
        "--data data/m14_merged.csv \\\n",
        "--output-dir artifacts \\\n",
        "--n-splits 5 --n-estimators 500"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZejNJLDHLtNH"
      },
      "outputs": [],
      "source": [
        "# !python tree_feature.py \\\n",
        "#   --data data/m14_merged.csv \\\n",
        "#   --output-dir artifacts2 \\\n",
        "#   --n-splits 5 \\\n",
        "#   --n-estimators 500 \\\n",
        "#   --drop-cols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmy-TGuS4bvT",
        "outputId": "7b3893ab-1308-41ac-972d-535d9935924a"
      },
      "outputs": [],
      "source": [
        "# Train RandomForest and XGBoost after removing the requested features\n",
        "# This loads the wrangled CSV, drops the columns, runs 5-fold Stratified CV, and prints accuracy and F1-macro.\n",
        "\n",
        "#%cd /content/WESAD\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# 1) Load data\n",
        "df = pd.read_csv(\"data/m14_merged.csv\")\n",
        "\n",
        "# 2) Columns to drop\n",
        "to_remove = ['EDA_tonic_min', 'ACC_x_min', 'ACC_y_min', 'ACC_z_min', 'TEMP_min', 'BVP_min']\n",
        "label_col = 'label'  # change if your label column is different\n",
        "\n",
        "# 3) Prepare X, y\n",
        "drop_cols = [c for c in to_remove if c in df.columns]\n",
        "X = df.drop(columns=[label_col] + drop_cols, errors='ignore')\n",
        "y = df[label_col].astype(int)\n",
        "\n",
        "print(\"Dropped columns:\", drop_cols)\n",
        "print(\"X shape:\", X.shape)\n",
        "\n",
        "# 4) 5-fold Stratified CV\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "rf_accs, rf_f1s = [], []\n",
        "xgb_accs, xgb_f1s = [], []\n",
        "\n",
        "for fold, (tr_idx, va_idx) in enumerate(skf.split(X, y), 1):\n",
        "    X_tr, X_va = X.iloc[tr_idx], X.iloc[va_idx]\n",
        "    y_tr, y_va = y.iloc[tr_idx], y.iloc[va_idx]\n",
        "\n",
        "    # RandomForest\n",
        "    rf = RandomForestClassifier(\n",
        "        n_estimators=500,\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    rf.fit(X_tr, y_tr)\n",
        "    rf_pred = rf.predict(X_va)\n",
        "    rf_accs.append(accuracy_score(y_va, rf_pred))\n",
        "    rf_f1s.append(f1_score(y_va, rf_pred, average='macro'))\n",
        "\n",
        "    # XGBoost\n",
        "    xgb = XGBClassifier(\n",
        "        n_estimators=500,\n",
        "        learning_rate=0.05,\n",
        "        max_depth=6,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        random_state=42,\n",
        "        n_jobs=-1,\n",
        "        tree_method='hist',\n",
        "        eval_metric='logloss'\n",
        "    )\n",
        "    xgb.fit(X_tr, y_tr)\n",
        "    xgb_pred = xgb.predict(X_va)\n",
        "    xgb_accs.append(accuracy_score(y_va, xgb_pred))\n",
        "    xgb_f1s.append(f1_score(y_va, xgb_pred, average='macro'))\n",
        "\n",
        "print(f\"RandomForest — Accuracy: {np.mean(rf_accs):.4f} ± {np.std(rf_accs):.4f} | F1-macro: {np.mean(rf_f1s):.4f} ± {np.std(rf_f1s):.4f}\")\n",
        "print(f\"XGBoost     — Accuracy: {np.mean(xgb_accs):.4f} ± {np.std(xgb_accs):.4f} | F1-macro: {np.mean(xgb_f1s):.4f} ± {np.std(xgb_f1s):.4f}\")\n",
        "\n",
        "\n",
        "# Save the reduced-feature results to artifacts\n",
        "import json, os\n",
        "os.makedirs(\"artifacts\", exist_ok=True)\n",
        "results = {\n",
        "    \"dropped_columns\": drop_cols,\n",
        "    \"rf_accuracy_mean\": float(np.mean(rf_accs)),\n",
        "    \"rf_accuracy_std\": float(np.std(rf_accs)),\n",
        "    \"rf_f1_macro_mean\": float(np.mean(rf_f1s)),\n",
        "    \"rf_f1_macro_std\": float(np.std(rf_f1s)),\n",
        "    \"xgb_accuracy_mean\": float(np.mean(xgb_accs)),\n",
        "    \"xgb_accuracy_std\": float(np.std(xgb_accs)),\n",
        "    \"xgb_f1_macro_mean\": float(np.mean(xgb_f1s)),\n",
        "    \"xgb_f1_macro_std\": float(np.std(xgb_f1s)),\n",
        "}\n",
        "with open(\"artifacts/reduced_features_results.json\", \"w\") as f:\n",
        "    json.dump(results, f, indent=2)\n",
        "print(\"Saved to artifacts/reduced_features_results.json\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "julia 1.11.5",
      "language": "julia",
      "name": "julia"
    },
    "language_info": {
      "file_extension": ".jl",
      "mimetype": "application/julia",
      "name": "julia",
      "version": "1.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
